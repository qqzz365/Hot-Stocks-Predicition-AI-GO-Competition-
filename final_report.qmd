---
title: "Hot Stocks Predicition(AI GO Competition)"
subtitle: "Final Report for Statistical Consulting Project"
date: today
author: Group 7 – 蔡秉言, 周君儒, 陳亭霓, 王皓渝, 孫亞瑄
format:
 pdf:
    include-in-header:
      - text: |
         \usepackage{setspace,relsize}
         \usepackage{geometry}
         \geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
mainfont: "Microsoft JhengHei Bold"
toc: true
lang: en #zh-Tw
documentclass: article
pdf-engine: xelatex
execute:
  tidy: true
  echo: true
  warning: false
  message: false
---

## Introduction
This report details our group’s efforts in the AI GO stock prediction competition. Our goal was to develop a binary classifier to identify “hot stocks” (飆股), characterized by significant price surges, using a comprehensive dataset of technical, fundamental, and brokerage-related features. A key challenge was the highly imbalanced label distribution, with only 0.73% of records classified as hot stocks, necessitating careful modeling strategies to prioritize the minority class.

## Data information
The training dataset comprised approximately 200,000 records and 10,212 features, each representing a stock’s status on a specific date. The table below summarizes the feature categories, their counts, and descriptions.

| Category        | Feature Item           | Count | Description                                                                 |
|-------------------|----------------------------------|-------|------------------------------------------------------------------------|
| Chip Analysis   | Net Buy/Sell (Top15)   | 9450  | Top 15 buying/selling brokers with 14 indicators each (volume, avg. price) |
|                 | Foreign Brokerages     | 105   | Aggregated trading metrics of foreign brokers                              |
|                 | Major Brokerages       | 105   | Aggregated trading data of large domestic brokerages                       |
|                 | Government Brokerages  | 17    | Trading activity from government-related brokers                           |
|                 | Individual Brokers     | 111   | Data for all individual brokers                                             |
|                 | Individual Main Force  | 15    | Top 15 individual investors with large positions                           |
|                 | Daily Foreign Trades   | 24    | Daily trading stats from foreign investors                                 |
|                 | Daily Proprietary      | 18    | Daily trades by proprietary dealers                                        |
|                 | Daily Investment Trust | 12    | Daily investment behavior of mutual fund managers                          |
| Fundamentals     | Quarterly IFRS Reports | 130   | Financial ratios from quarterly IFRS reports (e.g., ROE, EPS, margins)     |
|                 | Monthly Revenue        | 34    | Monthly sales data, growth rates, cumulative revenues                      |
| Technicals       | Technical Indicators   | 81    | Momentum and trend indicators like RSI, MACD, ADX, etc.                    |
|                 | Market Index           | 55    | Broader market index values (weighted, volume, etc.)                       |
|                 | Individual Stocks      | 55    | Computed technical values for each stock                                   |
| **Total**       |                        | 10212 | Total number of features used 

**Total number of features: 10212 (raw data)**

## Data Preprocessing

### Preprocessing Pipeline 1
To prepare the dataset for modeling, we implemented a robust preprocessing pipeline to handle missing values, encode categorical variables, transform skewed features, and normalize numerical data:

- **Handling Missing Values**: Dropped 16 columns with >40% NA and filled remaining numerical NA with zeros.
- **Categorical Encoding**: One-hot encoded `季IFRS財報_DPZ等級` and `季IFRS財報_Z等級` (10 categories each, including 'Missing').
- **Feature Transformation**: Applied shift-log transformation to 385 high-skew features.
- **Normalization**: Robust scaled 744 numerical columns using IQR-based RobustScaler.

### Preprocessing Pipeline 2
To enhance the dataset, we derived time-series-based features to capture temporal patterns:

- **Average Calculation**: Computed averages for grouped time-series data (e.g., 個股收盤價_group1_avg) across 1-20 days.
- **Difference Calculation**: Calculated log differences (6-day minus current) for grouped features (e.g., 個股收盤價_group1_diff).
- **OBV Calculation**: Derived On-Balance Volume (OBV) for 0-20 days using price and volume data.
- **PMV Calculation**: Computed Price Movement Volume (PMV) for 0-20 days based on price changes and volume.
- **Pipeline Execution**: Applied TAIEX and STK pipelines with OBV and PMV enabled, concatenating results with original data.


## Analysis Methods

Our modeling approach evolved over three stages, incorporating baseline modeling, feature selection, and advanced ensemble techniques to optimize performance on the imbalanced dataset.

### Stage 1: Single LightGBM Model with Cross-Validation

- Model Setup: We trained a LightGBM classifier with tuned parameters (e.g., num_leaves, learning_rate, scale_pos_weight). The scale_pos_weight was set based on the negative-to-positive sample ratio to address class imbalance.
- Cross-Validation: Used 10-fold stratified k-fold cross-validation to ensure consistent class distributions and robust out-of-fold (OOF) predictions, minimizing overfitting.
- Threshold Optimization: Evaluated predictions across thresholds (0.1 to 1.0) to maximize the F1 score, prioritizing minority class performance over accuracy, which is less informative in imbalanced settings.
- Rationale: This approach served as a baseline to establish initial model performance and feature insights. LightGBM was chosen for its computational efficiency and ability to handle high-dimensional, imbalanced data, making it ideal for rapid prototyping. The focus on F1 score and AUPRC ensured that the model prioritized the minority class, aligning with the task's objective of identifying rare positive instances (e.g., "飆股").

### Stage 2: Stacking with LightGBM and Logistic Regression

- Model Design: We implemented a stacking ensemble using three LightGBM models trained on distinct feature subsets: technical indicators, non-technical features, and all features. A Logistic Regression (LR) meta-model combined their OOF predictions to improve robustness.
- Feature Subsets: Splitting features into technical indicators (e.g., RSI, MACD) and others allowed us to capture diverse market signals.
- Training: Each LightGBM model was trained with 5-fold stratified cross-validation, with hyperparameters tuned via Optuna to maximize AUPRC. The LR meta-model was similarly optimized for parameters like C, solver, and penalty.
- Stacking Framework: OOF predictions from the three LightGBM models were used as features to train a Logistic Regression meta-model, also optimized via Optuna for parameters like C, solver, and penalty. LR was selected for its ability to linearly combine base model outputs, reducing overfitting risk compared to complex meta-models. Additionally, a weighted average of base model predictions (weighted by AUPRC scores) was computed as a benchmark to compare with the stacking approach.


### Stage 3: XGBoost with Feature Combination Ensembling

- Model Design: We trained XGBoost models on all possible combinations of three feature categories (“上市加權”, “技術指標”, “其他”) to explore feature interactions systematically. A weighted ensemble, based on AUPRC, combined predictions from high-performing models.
- Feature Combinations: Seven feature subsets (individual categories, pairwise combinations, and all features) were generated to identify optimal predictive signals.
- Training: Each XGBoost model used 5-fold stratified cross-validation with Optuna-optimized hyperparameters to maximize AUPRC. Parallel training reduced computational time.
- Rationale: XGBoost’s robustness to overfitting and flexibility in capturing feature interactions made it ideal for this stage. The ensemble approach prioritized models with strong minority class performance.

## Data Analysis and Results

We submitted eight model iterations, progressively refining our approach through stacking, threshold tuning, and feature engineering. The table below summarizes our submission results.

## Model Submission Results

| Submission | Score  | Recall | F1-score | Description                                      |
|------------|--------|--------|----------|--------------------------------------------------|
| 01         | 0.7040 | 0.8359 | 0.6080   | Baseline (Stage 1)                               |
| 02         | 0.7616 | 0.9127 | 0.6534   | First Feature Aggregation (2,842 features)       |
| 03         | 0.4893 | 1.0000 | 0.3239   | Second Feature Aggregation (111 features)        |
| 04         | 0.7122 | 0.9706 | 0.5625   | Second Aggregation + Threshold Adjustment        |
| 05         | 0.7964 | 0.8282 | 0.7670   | Stacking Baseline                                |
| 06         | 0.8148 | 1.0000 | 0.6875   | Stacking with LR (Stage 2)                       |
| 07         | 0.8266 | 1.0000 | 0.7045   | Third Feature Aggregation                        |
| 08         | 0.8344 | 1.0000 | 0.7159   | Stacking with XGBoost (Stage 3)                  |


We also explored other approaches, such as meta-sampling for imbalanced learning (MESA) for unbalanced data, and Principal Component Analysis (PCA) to reduce the high-dimensional feature space. However, these methods were not adopted due to integration challenges and limited performance gains.

## Conclusion

### Rank

Through iterative preprocessing, feature engineering, and ensemble modeling, we improved our model’s score from 0.7040 to 0.8344. Key takeaways include the critical role of domain-specific feature engineering and the need for robust techniques to address data imbalance. These efforts enabled us to rank **21st out of 848** teams in the competition.

### Experience Sharing

At Factors attending a finalist seminar, we gained valuable insights from top-performing teams. Notably, four of the top five teams incorporated brokerage identification codes (券商代號) into their feature engineering, identifying patterns where specific brokerage branches were linked to early-stage stock accumulations preceding price surges.

In contrast, our approach relied heavily on aggregated brokerage activity (e.g., buy/sell volumes) but did not encode individual brokerage identities. This likely limited our ability to capture nuanced institutional trading signals.

This observation underscores the value of entity-specific feature engineering in financial prediction tasks, where institutional behaviors can serve as leading indicators. In future projects, we plan to explore encoding brokerage identities to better leverage these signals, enhancing our model’s ability to detect predictive patterns.

This insight highlights the importance of domain-informed feature extraction, particularly in financial prediction tasks where entity-level effects (e.g., broker, institution) can serve as strong leading indicators. For future work, we plan to explore entity encoding methods to better leverage this class of signal.